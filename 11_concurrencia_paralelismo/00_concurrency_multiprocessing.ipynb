{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency ⚡️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads / async / multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asincronía vs paralelismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* enviar/recibir datos a través de la red\n",
    "* leer el contenido de un archivo dentro de nuestro programa\n",
    "* escribir datos de nuestro programa en el disco\n",
    "* esperar a que finalice una operación en una API remota\n",
    "* esperar a que finalice una operación en una base de datos \n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que puede ser paralelizado y que no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando llegamos a los detalles, solo el `multiprocessing` realmente ejecuta estos hilos de procesamiento literalmente al mismo tiempo.\n",
    "\n",
    "`threading` y `asyncio` se ejecutan en un único proceso y, por lo tanto, solo se ejecutan uno a la vez. Simplemente encuentran formas de turnarse para acelerar el proceso general. Aún así llamamos a esto concurrencia.\n",
    "\n",
    "* threading: multitarea apropiativa (OS. El SO decide.) https://es.wikipedia.org/wiki/Multitarea_apropiativa  \n",
    "* asyncio: multitarea cooperativa (Tu. Cada proceso cede el control.) https://es.wikipedia.org/wiki/Multitarea_cooperativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoria compartida vs replicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosas más lentas que la CPU; I/O o network bound.\n",
    "\n",
    "![I/O - networking](https://files.realpython.com/media/IOBound.4810a888b457.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No asociado a I/O, mucha computación; CPU bound.\n",
    "\n",
    "![](https://files.realpython.com/media/CPUBound.d2d32cb2626c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [\n",
    "    \"https://www.yahoo.com/\",\n",
    "    \"http://www.cnn.com\",\n",
    "    \"http://www.python.org\",\n",
    "    \"http://www.jython.org\",\n",
    "    \"http://www.pypy.org\",\n",
    "    \"http://www.perl.org\",\n",
    "    \"http://www.cisco.com\",\n",
    "    \"http://www.facebook.com\",\n",
    "    \"http://www.twitter.com\",\n",
    "    \"http://www.macrumors.com/\",\n",
    "    \"http://arstechnica.com/\",\n",
    "    \"http://www.reuters.com/\",\n",
    "    \"http://abcnews.go.com/\",\n",
    "    \"http://www.cnbc.com/\",\n",
    "    \"http://olympus.realpython.org/dice\",\n",
    "    \"https://realpython.com/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 244295 from https://www.yahoo.com/\n",
      "Read 1142002 from http://www.cnn.com\n",
      "Read 49886 from http://www.python.org\n",
      "Read 10394 from http://www.jython.org\n",
      "Read 6832 from http://www.pypy.org\n",
      "Read 12861 from http://www.perl.org\n",
      "Read 96543 from http://www.cisco.com\n",
      "Read 209853 from http://www.facebook.com\n",
      "Read 42523 from http://www.twitter.com\n",
      "Read 336513 from http://www.macrumors.com/\n",
      "Read 90569 from http://arstechnica.com/\n",
      "Read 203818 from http://www.reuters.com/\n",
      "Read 212963 from http://abcnews.go.com/\n",
      "Read 971874 from http://www.cnbc.com/\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 39789 from https://realpython.com/\n",
      "12.013489007949829\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def download_site(url):\n",
    "    response = requests.get(url)\n",
    "    return len(response.content)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for url int sites:\n",
    "    download_site(url)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10394 from http://www.jython.org\n",
      "Read 49886 from http://www.python.org\n",
      "Read 1142002 from http://www.cnn.com\n",
      "Read 6832 from http://www.pypy.org\n",
      "Read 96543 from http://www.cisco.com\n",
      "Read 12861 from http://www.perl.org\n",
      "Read 336467 from http://www.macrumors.com/\n",
      "Read 206758 from http://www.facebook.com\n",
      "Read 204144 from http://www.reuters.com/\n",
      "Read 245526 from https://www.yahoo.com/\n",
      "Read 90569 from http://arstechnica.com/\n",
      "Read 42523 from http://www.twitter.com\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 970282 from http://www.cnbc.com/\n",
      "Read 212963 from http://abcnews.go.com/\n",
      "Read 39789 from https://realpython.com/\n",
      "2.04518723487854\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def download_site(url):\n",
    "    response = requests.get(url)\n",
    "    return len(response.content)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    todos = [resultado for resultado in executor.map(download_site, sites)]\n",
    "\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parte del `Thread`. Eso es solo un hilo de procesamiento que mencionamos anteriormente. `Pool` es donde comienza a ponerse interesante. Este objeto va a crear un grupo de subprocesos, cada uno de los cuales puede ejecutarse simultáneamente. Finalmente, el `Executor` es la parte que controlará cómo y cuándo se ejecutará cada uno de los hilos del grupo.\n",
    "\n",
    "![](https://files.realpython.com/media/Threading.3eef48da829e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "# from threading import Lock\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "l = Lock()\n",
    "\n",
    "def increment_counter(fake_value):\n",
    "    # l.acquire()\n",
    "    with l:\n",
    "        global counter\n",
    "        for _ in range(100):\n",
    "            counter += 1\n",
    "    # l.release()\n",
    "\n",
    "\n",
    "fake_data = [x for x in range(5000)]\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    executor.map(increment_counter, fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general concept of asyncio is that a single Python object, called the event loop, controls how and when each task gets run. The event loop is aware of each task and knows what state it’s in. In reality, there are many states that tasks could be in, but for now let’s imagine a simplified event loop that just has two states.\n",
    "\n",
    "The ready state will indicate that a task has work to do and is ready to be run, and the waiting state means that the task is waiting for some external thing to finish, such as a network operation.\n",
    "\n",
    "Your simplified event loop maintains two lists of tasks, one for each of these states. It selects one of the ready tasks and starts it back to running. That task is in complete control until it cooperatively hands the control back to the event loop.\n",
    "\n",
    "When the running task gives control back to the event loop, the event loop places that task into either the ready or waiting list and then goes through each of the tasks in the waiting list to see if it has become ready by an I/O operation completing. It knows that the tasks in the ready list are still ready because it knows they haven’t run yet.\n",
    "\n",
    "Once all of the tasks have been sorted into the right list again, the event loop picks the next task to run, and the process repeats. Your simplified event loop picks the task that has been waiting the longest and runs that. This process repeats until the event loop is finished.\n",
    "\n",
    "An important point of asyncio is that the tasks never give up control without intentionally doing so. They never get interrupted in the middle of an operation. This allows us to share resources a bit more easily in asyncio than in threading. You don’t have to worry about making your code thread-safe.\n",
    "\n",
    "**Any function that calls await needs to be marked with async. You’ll get a syntax error otherwise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay que preocuparse del número de threads que crear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://markhneedham.com/blog/2019/05/10/jupyter-runtimeerror-this-event-loop-is-already-running/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(download_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 45718 from http://www.reuters.com/\n",
      "Read 12861 from http://www.perl.org\n",
      "Read 49886 from http://www.python.org\n",
      "Read 3586 from http://www.jython.org\n",
      "Read 153581 from http://www.cnbc.com/\n",
      "Read 20418 from http://www.cisco.com\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read None from http://www.macrumors.com/\n",
      "Read None from https://realpython.com/\n",
      "Read 157341 from http://www.cnn.com\n",
      "Read None from http://www.facebook.com\n",
      "Read 6832 from http://www.pypy.org\n",
      "Read 50102 from http://abcnews.go.com/\n",
      "Read None from http://arstechnica.com/\n",
      "Read None from http://www.twitter.com\n",
      "Read None from https://www.yahoo.com/\n",
      "Downloaded 16 sites in 1.0771641731262207 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "async def download_site(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        # result = await response.content_length\n",
    "        print(\"Read {0} from {1}\".format(response.content_length, url))\n",
    "\n",
    "\n",
    "async def download_all_sites(sites):\n",
    "    # You can share the session across all tasks, so the session is created here as a context manager.\n",
    "    # The tasks can share the session because they are all running on the same thread.\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in sites:\n",
    "            # ensure_future also takes care of starting the tasks\n",
    "            task = asyncio.ensure_future(download_site(session, url))\n",
    "            tasks.append(task)\n",
    "        # print(tasks)\n",
    "        # Once all the tasks are created, this function uses asyncio.gather()\n",
    "        # to keep the session context alive until all of the tasks have completed.\n",
    "        await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "await download_all_sites(sites)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(sites)} sites in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://files.realpython.com/media/Asyncio.31182d3731cf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENCIÓN**\n",
    "\n",
    "**ATENCIÓN**\n",
    "\n",
    "**ATENCIÓN**\n",
    "\n",
    "Las siguientes celdas demuestran como descargar un set de imágenes aleatorias de la API de [unsplash](https://unsplash.com/). Una de las celdas las escribe en una carpeta `images/` la otra en `images2/`.\n",
    "\n",
    "\n",
    "En la carpeta donde está este notebook están estas dos carpetas vacias. Pero revisa todo bien para que no se sobreescriba nada que no quieras.\n",
    "\n",
    "Las celdas están aquí para demostrar como descargar muchas imágenes de forma asíncrona usando [aiohtpp](https://docs.aiohttp.org/en/stable/) en el primer caso, y [httpx](https://github.com/encode/httpx) en el segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 22.2 µs\n",
      "total = 4.9483451249998325\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "from string import ascii_lowercase, printable\n",
    "from random import choice\n",
    "\n",
    "\n",
    "def random_string(string_length=15):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = ascii_lowercase\n",
    "    return \"\".join(choice(letters) for i in range(string_length))\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "\n",
    "\n",
    "async def download_site(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        c = await response.read()\n",
    "        await write_file(c)\n",
    "\n",
    "\n",
    "async def write_file(content):\n",
    "\n",
    "    filename = \"images/\" + random_string() + \".jpg\"\n",
    "    async with aiofiles.open(filename, mode=\"wb\") as f:\n",
    "        await f.write(content)\n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://source.unsplash.com/1600x900/?nature,water,\" + random_string(6)\n",
    "    for _ in range(50)\n",
    "]\n",
    "\n",
    "\n",
    "async def dl():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            task = asyncio.ensure_future(download_site(session, url))\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "await dl()\n",
    "print(f\"total = {time.perf_counter() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = 6.267024283999945\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from random import choice\n",
    "\n",
    "\n",
    "def random_string(string_length=15):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = ascii_lowercase\n",
    "    return \"\".join(choice(letters) for i in range(string_length))\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import httpx\n",
    "import aiofiles\n",
    "\n",
    "\n",
    "async def download_site(client, url):\n",
    "    r = await client.get(url)\n",
    "    await write_file(r.content)\n",
    "\n",
    "\n",
    "async def write_file(content):\n",
    "\n",
    "    filename = \"images2/\" + random_string() + \".jpg\"\n",
    "    async with aiofiles.open(filename, mode=\"wb\") as f:\n",
    "        await f.write(content)\n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://source.unsplash.com/1600x900/?nature,water,\" + random_string(10)\n",
    "    for _ in range(50)\n",
    "]\n",
    "\n",
    "\n",
    "async def dl():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            task = asyncio.ensure_future(download_site(client, url))\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "await dl()\n",
    "print(f\"total = {time.perf_counter() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio opcional, leer y entender este código: https://pybay.com/site_media/slides/raymond2017-keynote/async_examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://gist.github.com/bradmontgomery/81d71e415b0ff693f00408388590acb9\n",
    "\n",
    "import hashlib\n",
    "import sys\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from time import sleep, time\n",
    "\n",
    "\n",
    "def t1(n):\n",
    "    \"\"\"Silly function whose time increases as n does, it increases linearly.\"\"\"\n",
    "    for i in range(n):\n",
    "        if i % 2 == 0:\n",
    "            sleep(0.5)\n",
    "\n",
    "\n",
    "def t2(n):\n",
    "    \"\"\"A somewhat CPU-intensive task.\"\"\"\n",
    "    for i in range(n):\n",
    "        hashlib.pbkdf2_hmac(\"sha256\", b\"password\", b\"salt\", 100000)\n",
    "\n",
    "\n",
    "def do_work(n):\n",
    "    \"\"\"Function that does t1 and t2 in serial.\"\"\"\n",
    "    start = time()\n",
    "    t1(n)\n",
    "    t2(n)\n",
    "    end = time()\n",
    "    print(\"Work for {} finished in {}s\".format(n, round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial():\n",
    "\n",
    "    start = time()\n",
    "    for x in range(10):\n",
    "        do_work(x)\n",
    "    end = time()\n",
    "    print(\"All work finished in {}s\".format(round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel():\n",
    "    start = time()\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        inputs = range(10)\n",
    "        for x, result in zip(inputs, executor.map(do_work, inputs)):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"All work finished in {}s\".format(round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work for 0 finished in 0.0s\n",
      "Work for 1 finished in 0.59s\n",
      "Work for 2 finished in 0.66s\n",
      "Work for 3 finished in 1.26s\n",
      "Work for 4 finished in 1.4s\n",
      "Work for 5 finished in 1.93s\n",
      "Work for 6 finished in 2.05s\n",
      "Work for 7 finished in 2.58s\n",
      "Work for 8 finished in 2.69s\n",
      "Work for 9 finished in 3.25s\n",
      "All work finished in 16.42s\n"
     ]
    }
   ],
   "source": [
    "serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work for 0 finished in 0.0s\n",
      "Work for 1 finished in 0.63s\n",
      "Work for 2 finished in 0.78s\n",
      "Work for 3 finished in 1.32s\n",
      "Work for 4 finished in 1.4s\n",
      "Work for 5 finished in 1.9s\n",
      "Work for 6 finished in 2.36s\n",
      "Work for 7 finished in 2.75s\n",
      "Work for 8 finished in 2.79s\n",
      "Work for 9 finished in 3.22s\n",
      "All work finished in 5.75s\n"
     ]
    }
   ],
   "source": [
    "parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "* Escribe un script que identifique todas las imágenes de un árbol de carpetas.\n",
    "* Debemos obtener una lista con todas las rutas de archivo de las imagénes.\n",
    "* Crear una función que covierta una imagen a 128x128. Usar la librería **Pillow**, ya viene instalada en vuestra distribución de Anaconda creo.\n",
    "\n",
    "```python\n",
    "from PIL import Image\n",
    "````\n",
    "\n",
    "* Tras convertir una imagen, todas deben estar guardadaes en una misma carpeta. Por ejemplo al final habrá una carpeta que se llame \"miniaturas\" que contendrá todas las imágenes convertidas.\n",
    "* Cada imagen debe convertirla en un thumbnail (128x128) y guardarlas en una misma carpeta.\n",
    "* Cuando guardemos la imagen debemos guardarla con su nombre original añadiendo \"_thumbnail\".\n",
    "    Por ejemplo `imagen.jpg` -> `imagen_thumbnail.jpg`\n",
    "\n",
    "Intentar usar un f-string para el path `(f\"carpeta/{}_{}.jpg\")`.\n",
    "\n",
    "* **Importante**: una vez tengamos la lista con todas nuestras rutas de archivo. Hay que usar procesamiento en paralelo para convertir las imágenes. Por ejemplo un ThreadPoolExecutor o ProcessPoolExecutor.\n",
    "\n",
    "**Extra**:\n",
    "\n",
    "En el módulo `functools` de Python existe una cosa que se llama `partial`. Esta función nos permite crea lo que se llaman funciones parciales. Si tenemos una función que por ejemplo acepta 3 argumentos, crear una función parcial sería *\"duplicar\"* está función pero haciendo que uno de estos parámetros sea fijo. Y obtendríamos una función. Por ejemplo:\n",
    "\n",
    "* Tengo una función: `convertir_miniatura(resolucion, ruta)`\n",
    "* Puedo hacer `miniatura128 = partial(convertir_miniatura, 128)`.\n",
    "* Esto último me devolvería otra función, que ahora puedo utilizar directamente con: `miniatura128(\"/Users/r/.../imagen.jpg\")`. Tendremos a nuestra disposición una nueva función que es igual que la original pero como si uno de sus parámetros estuviera fijo.\n",
    "\n",
    "\n",
    "`functools.partial` + executors Pillow + paths (download images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "with open(\"archivo_ejercicio.zip\", \"wb\") as f:\n",
    "    f.write(\n",
    "        requests.get(\n",
    "            \"https://github.com/polyrand/teach/raw/master/11_concurrencia_paralelismo/archivo_ejercicio.zip\"\n",
    "        ).content\n",
    "    )\n",
    "\n",
    "with zipfile.ZipFile(\"archivo_ejercicio.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio pistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filelist = []\n",
    "\n",
    "for _, _, _ in os.walk(\"tree\"):\n",
    "    # os.walk itera sobre 3 parámetros, cuales son?\n",
    "    # hacer algo\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"tree/fdjtoupvvurxgrd.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/r/Projects/teach/11_concurrencia_paralelismo/tree/fdjtoupvvurxgrd.jpg')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.absolute()  # <<-- es una función, hay que poner ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fdjtoupvvurxgrd.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.name  # es un método, NO hay que poner ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fdjtoupvvurxgrd'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem  # es un método, NO hay que poner ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_nombre = p.stem + \"_thumbnail\" + p.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniaturas = Path(\"miniaturas/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('miniaturas/fdjtoupvvurxgrd_thumbnail.jpg')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miniaturas/nuevo_nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniaturizar(path: str):\n",
    "    size = (128, 128)  # 128x128\n",
    "    p = Path(path).absolute()\n",
    "    nuevo_nombre = p.stem + \"_thumbnail\" + p.suffix\n",
    "    miniaturas = Path(\"miniaturas/\").absolute()\n",
    "    save = miniaturas / nuevo_nombre\n",
    "    image = Image.open(p)\n",
    "    image.thumbnail(size)\n",
    "    image.save(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Donald Knuth](https://en.wikipedia.org/wiki/Donald_Knuth): “Premature optimization is the root of all evil (or at least most of it) in programming.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más info y fuentes:\n",
    "\n",
    "* https://realpython.com/python-concurrency/ 👈🏼\n",
    "* https://realpython.com/intro-to-python-threading/\n",
    "* https://www.youtube.com/watch?v=9zinZmE3Ogk\n",
    "* https://pybay.com/site_media/slides/raymond2017-keynote/index.html\n",
    "* https://realpython.com/async-io-python/  👈🏼 lectura recomendada, async es un tema complejo y tiene su curva de apredizaje\n",
    "* https://realpython.com/intro-to-python-threading/\n",
    "* https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python\n",
    "* https://stackoverflow.com/questions/49005651/how-does-asyncio-actually-work/51116910#51116910\n",
    "* https://www.blog.pythonlibrary.org/2016/07/26/python-3-an-intro-to-asyncio/\n",
    "* https://stackabuse.com/python-async-await-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teach",
   "language": "python",
   "name": "teach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
